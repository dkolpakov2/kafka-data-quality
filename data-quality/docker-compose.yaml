#version: "3.9"

services:
  # ============================================================
  # ZOOKEEPER
  # ============================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  # ============================================================
  # KAFKA BROKER
  # ============================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
# ============================================================
# KAFKA REST PROXY for easy producing/consuming via REST API
# ============================================================

  rest-proxy:
    image: confluentinc/cp-kafka-rest:7.5.0
    depends_on:
      - kafka
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_BOOTSTRAP_SERVERS: "kafka:9092"
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"      
# ============================================================
# KAFDROP - KAFKA WEB UI 
# ============================================================
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    depends_on:
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092      
# ============================================================
# KAFKA SEEDER
# ============================================================
  kafka-seeder:
    image: python:3.10-slim
    container_name: kafka-seeder
    depends_on:
      - kafka
    #command: [ "python", "/app/seeder.py" ]
    working_dir: /app
    command: >
      sh -c "pip install --no-cache-dir -r requirements.txt &&
           python seeder.py"
    environment:
      KAFKA_BROKER: "kafka:9092"
      KAFKA_TOPIC: "topic_onprem_sales"
      MESSAGE_RATE: "1"         # messages per second
      MESSAGE_LIMIT: "100"      # total messages to send
    volumes:
      - ./kafka-seeder:/app
  # ============================================================
  # CASSANDRA (ON-PREM)
  # ============================================================
  cassandra_onprem:
    image: cassandra:4.1
    container_name: cassandra_onprem
    environment:
      CASSANDRA_CLUSTER_NAME: "OnPremCluster"
      CASSANDRA_DC: "DC_ONPREM"
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
      CASSANDRA_NUM_TOKENS: 256   # default
    ports:
      - "9042:9042"
    volumes:
      - cassandra_onprem_data:/var/lib/cassandra

  # ============================================================
  # CASSANDRA (CLOUD - SIMULATED)
  # ============================================================
  cassandra_cloud:
    image: cassandra:4.1
    container_name: cassandra_cloud
    environment:
      CASSANDRA_CLUSTER_NAME: "CloudCluster"
      CASSANDRA_DC: "DC_AZURE"
      CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
      CASSANDRA_NUM_TOKENS: 256   # default
    ports:
      - "9142:9042"
    volumes:
      - cassandra_cloud_data:/var/lib/cassandra

  # ============================================================
  # FLINK
  # ============================================================
  jobmanager:
    image: flink:1.17-scala_2.12
    container_name: flink_jobmanager
    depends_on:
      - kafka    
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager

  taskmanager:
    image: flink:1.17-scala_2.12
    #container_name: flink_taskmanager
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      # JobManager host
      jobmanager.rpc.address: flink_jobmanager          # or docker service name
      # Flink REST endpoint
      rest.address: flink_jobmanager
      rest.port: 8081
      # SQL Gateway specific
      sql-gateway.endpoint.rest.address: 0.0.0.0
      sql-gateway.endpoint.rest.port: 8083    
      #- JOB_MANAGER_RPC_ADDRESS=jobmanager
      FLINK_PROPERTIES: |
       jobmanager.rpc.address: jobmanager
       taskmanager.numberOfTaskSlots: 4
    deploy:
      replicas: 2

  ### ============================================================
  # SQL GATEWAY (for Flink SQL)
  # ============================================================
  sql-gateway:
    image: flink:1.17.1
    container_name: sql-gateway
    depends_on:
      - jobmanager
    ports:
      - "8083:8083"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        rest.address: flink-jobmanager
        sql-gateway.endpoint.rest.address: 0.0.0.0
        sql-gateway.endpoint.rest.port: 8083
    command: /opt/flink/bin/sql-gateway.sh start-foreground      
    # command: >
    #   bash -c "
    #   ./bin/sql-gateway.sh start
    #   -Dsql-gateway.endpoint.rest.address=0.0.0.0
    #   -Dsql-gateway.endpoint.rest.port=8083
    #   -Dexecution.target=remote
    #   -Dexecution.remote.host=jobmanager
    #   -Dexecution.remote.port=8081
    #   "
  # ============================================================
  # ZEPPELIN (Flink SQL Notebooks)
  # ============================================================
  zeppelin:
    image: apache/zeppelin:0.11.1
    container_name: zeppelin
    # Option2 REMOVED: flink jar inside of zeppelin image , switch to option 1
    # build:
    #    context: .
    #    dockerfile: zeppelin/Dockerfile-zeppelin-flink
    depends_on:
      - sql-gateway
    #  - jobmanager
    #  - taskmanager
    ports:
      - "8080:8080"
    environment:
      # ZEPPELIN_JAVA_OPTS: >
      #   -Dzeppelin.flink.useLocalFlink=true
      #   -Dzeppelin.flink.ui.enabled=true
      #   -Dzeppelin.flink.run.as.session=true
      #   -DFLINK_HOME=/opt/flink
      #   -Dzeppelin.flink.runMode=remote
      #   -Dzeppelin.flink.remote.host=jobmanager
      ZEPPELIN_NOTEBOOK_DIR: /zeppelin/notebook
      # Interpreter configuration can be updated via Zeppelin UI:
      # %flink.ssql -> Execution Mode: Remote, Remote Host: sql-gateway, Remote Port: 8083      
    volumes:
      #- ./flink-1.17.1:/opt/flink
      - ./zeppelin/notebooks:/zeppelin/notebook
      - ./zeppelin/conf:/zeppelin/conf
      - /usr/lib/zeppelin/interpreter
    # Interpreter configuration can be updated via Zeppelin UI:
    # %flink.ssql -> Execution Mode: Remote, Remote Host: sql-gateway, Remote Port: 8083      
  # ============================================================
  # PYTHON DQ RULE GENERATOR (OPTIONAL)
  # ============================================================
  # dq_generator:
  #   build:
  #     context: ./tools
  #   container_name: dq_sql_generator
  #   volumes:
  #     - ./rules:/rules
  #     - ./generated_sql:/generated_sql
  #   command: >
  #     python rules_to_sql.py /rules/rules.yaml --output /generated_sql/compiled.sql

  # ============================================================
  # DATADOG AGENT (metrics from valid/invalid counters)
  # ============================================================
  datadog:
    image: gcr.io/datadoghq/agent:latest
    environment:
      DD_API_KEY: "${DD_API_KEY}"
      DD_SITE: "datadoghq.com"
      DD_LOGS_ENABLED: "true"
      DD_CONTAINER_EXCLUDE: "name:datadog"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro

volumes:
  cassandra_onprem_data:
  cassandra_cloud_data:
