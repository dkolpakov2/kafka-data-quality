{
  "paragraphs": [
    {
      "title": "01 Kafka Source (Cloud)",
      "text": "%flink.ssql\nCREATE TABLE kafka_cloud_source (\n  id STRING,\n  event_ts TIMESTAMP(3),\n  value DOUBLE,\n  raw_json STRING,\n  WATERMARK FOR event_ts AS event_ts - INTERVAL \u00275\u0027 SECOND\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027topic_cloud_sales\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.065",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387065_1651125172",
      "id": "paragraph_1766770387035_1801134040",
      "dateCreated": "2025-12-26 17:33:07.065",
      "status": "READY"
    },
    {
      "title": "02 DQ Enrichment + Canonical Hash",
      "text": "%flink.ssql\nCREATE VIEW dq_enriched AS\nSELECT\n  id,\n  event_ts,\n  value,\n  SHA256(\n    CONCAT_WS(\u0027|\u0027,\n      COALESCE(id, \u0027NULL\u0027),\n      COALESCE(CAST(value AS STRING), \u0027NULL\u0027),\n      CAST(event_ts AS STRING)\n    )\n  ) AS record_hash,\n  raw_json\nFROM kafka_cloud_source;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.066",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387066_1869558060",
      "id": "paragraph_1766770387035_1809310723",
      "dateCreated": "2025-12-26 17:33:07.066",
      "status": "READY"
    },
    {
      "title": "03 Data Quality Rules",
      "text": "%flink.ssql\nCREATE VIEW dq_rules AS\nSELECT *,\n  CASE\n    WHEN id IS NULL THEN \u0027FAIL_ID_NULL\u0027\n    WHEN value \u003c 0 THEN \u0027FAIL_NEG_VALUE\u0027\n    WHEN event_ts IS NULL THEN \u0027FAIL_TS_NULL\u0027\n    ELSE \u0027PASS\u0027\n  END AS dq_status\nFROM dq_enriched;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_2003727650",
      "id": "paragraph_1766770387035_309098266",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    },
    {
      "title": "04 Cassandra Sink (Azure Cloud)",
      "text": "%flink.ssql\nCREATE TABLE cassandra_cloud_sink (\n  id STRING,\n  event_ts TIMESTAMP(3),\n  value DOUBLE,\n  record_hash STRING,\n  PRIMARY KEY (id) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027cassandra\u0027,\n  \u0027keyspace\u0027 \u003d \u0027sales\u0027,\n  \u0027table\u0027 \u003d \u0027events\u0027,\n  \u0027hosts\u0027 \u003d \u0027cassandra-cloud.internal\u0027,\n  \u0027datacenter\u0027 \u003d \u0027DC_AZURE\u0027\n);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_135798575",
      "id": "paragraph_1766770387035_1437969517",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    },
    {
      "title": "05 Insert Valid Records",
      "text": "%flink.ssql\nINSERT INTO cassandra_cloud_sink\nSELECT id, event_ts, value, record_hash\nFROM dq_rules\nWHERE dq_status \u003d \u0027PASS\u0027;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_318798960",
      "id": "paragraph_1766770387035_1594671148",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    },
    {
      "title": "06 DLQ – Invalid Records",
      "text": "%flink.ssql\nCREATE TABLE dq_dlq_cloud (\n  id STRING,\n  event_ts TIMESTAMP(3),\n  value DOUBLE,\n  record_hash STRING,\n  dq_status STRING,\n  raw_json STRING\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027dq_dlq_cloud\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);\n\nINSERT INTO dq_dlq_cloud\nSELECT id, event_ts, value, record_hash, dq_status, raw_json\nFROM dq_rules\nWHERE dq_status \u003c\u003e \u0027PASS\u0027;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_449880407",
      "id": "paragraph_1766770387035_2044625022",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    },
    {
      "title": "07 Valid Row Counter",
      "text": "%flink.ssql\nCREATE TABLE dq_valid_metrics (\n  job_name STRING,\n  metric_ts TIMESTAMP(3),\n  valid_count BIGINT\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027dq_metrics_valid\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);\n\nINSERT INTO dq_valid_metrics\nSELECT\n  \u0027flink_cloud_job\u0027 AS job_name,\n  TUMBLE_END(event_ts, INTERVAL \u00271\u0027 MINUTE) AS metric_ts,\n  COUNT(*) AS valid_count\nFROM dq_rules\nWHERE dq_status \u003d \u0027PASS\u0027\nGROUP BY TUMBLE(event_ts, INTERVAL \u00271\u0027 MINUTE);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_1235861476",
      "id": "paragraph_1766770387037_1251525946",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    },
    {
      "title": "08 Invalid Row Counter",
      "text": "%flink.ssql\nCREATE TABLE dq_invalid_metrics (\n  job_name STRING,\n  metric_ts TIMESTAMP(3),\n  invalid_count BIGINT\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027dq_metrics_invalid\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);\n\nINSERT INTO dq_invalid_metrics\nSELECT\n  \u0027flink_cloud_job\u0027 AS job_name,\n  TUMBLE_END(event_ts, INTERVAL \u00271\u0027 MINUTE) AS metric_ts,\n  COUNT(*) AS invalid_count\nFROM dq_rules\nWHERE dq_status \u003c\u003e \u0027PASS\u0027\nGROUP BY TUMBLE(event_ts, INTERVAL \u00271\u0027 MINUTE);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:07.067",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770387067_1809771363",
      "id": "paragraph_1766770387037_1312385992",
      "dateCreated": "2025-12-26 17:33:07.067",
      "status": "READY"
    }
  ],
  "name": "Flink SQL Data Quality – Cassandra Cloud",
  "id": "2MCW1R21V",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}