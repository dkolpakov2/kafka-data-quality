{
  "paragraphs": [
    {
      "text": "%flink.bsql\nSELECT 1;",
      "user": "anonymous",
      "dateUpdated": "2026-01-02 14:32:17.400",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.zeppelin.interpreter.InterpreterException: org.apache.zeppelin.interpreter.InterpreterException: java.lang.NoClassDefFoundError: org/apache/flink/table/client/util/ClientWrapperClassLoader\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:76)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:861)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:769)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:186)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:135)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.zeppelin.interpreter.InterpreterException: java.lang.NoClassDefFoundError: org/apache/flink/table/client/util/ClientWrapperClassLoader\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:76)\n\tat org.apache.zeppelin.interpreter.Interpreter.getInterpreterInTheSameSessionByClassName(Interpreter.java:322)\n\tat org.apache.zeppelin.interpreter.Interpreter.getInterpreterInTheSameSessionByClassName(Interpreter.java:333)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.open(FlinkSqlInterpreter.java:43)\n\tat org.apache.zeppelin.flink.FlinkBatchSqlInterpreter.open(FlinkBatchSqlInterpreter.java:36)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\t... 8 more\nCaused by: java.lang.NoClassDefFoundError: org/apache/flink/table/client/util/ClientWrapperClassLoader\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:315)\n\tat org.apache.zeppelin.flink.FlinkShims.loadShims(FlinkShims.java:71)\n\tat org.apache.zeppelin.flink.FlinkShims.getInstance(FlinkShims.java:89)\n\tat org.apache.zeppelin.flink.FlinkScalaInterpreter.initFlinkConfig(FlinkScalaInterpreter.scala:158)\n\tat org.apache.zeppelin.flink.FlinkScalaInterpreter.open(FlinkScalaInterpreter.scala:122)\n\tat org.apache.zeppelin.flink.FlinkInterpreter.open(FlinkInterpreter.java:71)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\t... 13 more\nCaused by: java.lang.ClassNotFoundException: org.apache.flink.table.client.util.ClientWrapperClassLoader\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\t... 21 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770413956_2017287123",
      "id": "paragraph_1766770413956_2017287123",
      "dateCreated": "2025-12-26 17:33:33.956",
      "dateStarted": "2026-01-02 14:32:17.416",
      "dateFinished": "2026-01-02 14:32:20.850",
      "status": "ERROR"
    },
    {
      "title": "01 Kafka Source",
      "text": "%flink.ssql\nCREATE TABLE kafka_onprem_source (\n  id STRING,\n  event_ts TIMESTAMP(3),\n  value DOUBLE,\n  raw_json STRING,\n  WATERMARK FOR event_ts AS event_ts - INTERVAL \u00275\u0027 SECOND\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027topic_onprem_sales\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);",
      "user": "anonymous",
      "dateUpdated": "2025-12-31 21:09:53.990",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "java.lang.NullPointerException\n\tat java.base/java.util.Arrays.stream(Arrays.java:5614)\n\tat org.apache.zeppelin.interpreter.launcher.FlinkInterpreterLauncher.chooseFlinkAppJar(FlinkInterpreterLauncher.java:139)\n\tat org.apache.zeppelin.interpreter.launcher.FlinkInterpreterLauncher.buildEnvFromProperties(FlinkInterpreterLauncher.java:84)\n\tat org.apache.zeppelin.interpreter.launcher.StandardInterpreterLauncher.launchDirectly(StandardInterpreterLauncher.java:76)\n\tat org.apache.zeppelin.interpreter.launcher.InterpreterLauncher.launch(InterpreterLauncher.java:106)\n\tat org.apache.zeppelin.interpreter.InterpreterSetting.createInterpreterProcess(InterpreterSetting.java:856)\n\tat org.apache.zeppelin.interpreter.ManagedInterpreterGroup.getOrCreateInterpreterProcess(ManagedInterpreterGroup.java:66)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getOrCreateInterpreterProcess(RemoteInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:153)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:125)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:270)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:428)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:68)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:186)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:135)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:186)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394583_274626261",
      "id": "paragraph_1766770394568_845066582",
      "dateCreated": "2025-12-26 17:33:14.583",
      "dateStarted": "2025-12-31 21:09:54.006",
      "dateFinished": "2025-12-31 21:09:54.009",
      "status": "ERROR"
    },
    {
      "title": "02 DQ Enrichment + Hash",
      "text": "%flink.ssql\nCREATE VIEW dq_enriched AS\nSELECT\n  id,\n  event_ts,\n  value,\n  SHA256(\n    CONCAT_WS(\u0027|\u0027,\n      COALESCE(id, \u0027NULL\u0027),\n      COALESCE(CAST(value AS STRING), \u0027NULL\u0027),\n      CAST(event_ts AS STRING)\n    )\n  ) AS record_hash,\n  raw_json\nFROM kafka_onprem_source;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_1928651366",
      "id": "paragraph_1766770394568_836582389",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    },
    {
      "title": "03 Rule Evaluation",
      "text": "%flink.ssql\nCREATE VIEW dq_rules AS\nSELECT *,\n  CASE\n    WHEN id IS NULL THEN \u0027FAIL_ID_NULL\u0027\n    WHEN value \u003c 0 THEN \u0027FAIL_NEG_VALUE\u0027\n    WHEN event_ts IS NULL THEN \u0027FAIL_TS_NULL\u0027\n    ELSE \u0027PASS\u0027\n  END AS dq_status\nFROM dq_enriched;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_776254880",
      "id": "paragraph_1766770394568_1475982754",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    },
    {
      "title": "04 Cassandra Sink (OnPrem)",
      "text": "%flink.ssql\nCREATE TABLE cassandra_onprem_sink (\n  id STRING,\n  event_ts TIMESTAMP(3),\n  value DOUBLE,\n  record_hash STRING,\n  PRIMARY KEY (id) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027cassandra\u0027,\n  \u0027keyspace\u0027 \u003d \u0027sales\u0027,\n  \u0027table\u0027 \u003d \u0027events\u0027,\n  \u0027hosts\u0027 \u003d \u002710.10.0.5,10.10.0.6\u0027,\n  \u0027datacenter\u0027 \u003d \u0027DC_ONPREM\u0027\n);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_1942976770",
      "id": "paragraph_1766770394568_988127519",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    },
    {
      "title": "05 Insert Valid Rows",
      "text": "%flink.ssql\nINSERT INTO cassandra_onprem_sink\nSELECT id, event_ts, value, record_hash\nFROM dq_rules\nWHERE dq_status \u003d \u0027PASS\u0027;",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_1480245428",
      "id": "paragraph_1766770394568_1742348360",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    },
    {
      "title": "06 Valid Row Counter",
      "text": "%flink.ssql\nCREATE TABLE dq_valid_metrics (\n  job_name STRING,\n  metric_ts TIMESTAMP(3),\n  valid_count BIGINT\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027dq_metrics_valid\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);\n\nINSERT INTO dq_valid_metrics\nSELECT\n  \u0027flink_onprem_job\u0027 AS job_name,\n  TUMBLE_END(event_ts, INTERVAL \u00271\u0027 MINUTE) AS metric_ts,\n  COUNT(*) AS valid_count\nFROM dq_rules\nWHERE dq_status \u003d \u0027PASS\u0027\nGROUP BY TUMBLE(event_ts, INTERVAL \u00271\u0027 MINUTE);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_1560989352",
      "id": "paragraph_1766770394568_816581517",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    },
    {
      "title": "07 Invalid Row Counter",
      "text": "%flink.ssql\nCREATE TABLE dq_invalid_metrics (\n  job_name STRING,\n  metric_ts TIMESTAMP(3),\n  invalid_count BIGINT\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027dq_metrics_invalid\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027kafka:9092\u0027,\n  \u0027format\u0027 \u003d \u0027json\u0027\n);\n\nINSERT INTO dq_invalid_metrics\nSELECT\n  \u0027flink_onprem_job\u0027 AS job_name,\n  TUMBLE_END(event_ts, INTERVAL \u00271\u0027 MINUTE) AS metric_ts,\n  COUNT(*) AS invalid_count\nFROM dq_rules\nWHERE dq_status \u003c\u003e \u0027PASS\u0027\nGROUP BY TUMBLE(event_ts, INTERVAL \u00271\u0027 MINUTE);",
      "user": "anonymous",
      "dateUpdated": "2025-12-26 17:33:14.584",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1766770394584_1158824025",
      "id": "paragraph_1766770394568_710413429",
      "dateCreated": "2025-12-26 17:33:14.584",
      "status": "READY"
    }
  ],
  "name": "Flink SQL Data Quality â€“ OnPrem Cassandra",
  "id": "2MCK88QBA",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}